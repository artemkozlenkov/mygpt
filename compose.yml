services:
  litellm:
    image: ghcr.io/berriai/litellm:main-v1.53.1
    ports:
      - "4000:4000"
    depends_on:
      - db
    volumes:
      - ./litellm_config.yaml:/app/config.yaml
    environment:
      DATABASE_URL: postgres://llmproxy:dbpassword9090@db:5432/litellm
      STORE_MODEL_IN_DB: "True"
      LITELLM_MASTER_KEY: "sk-124781258123"
      LITELLM_TLS_ENABLED: "True"
    env_file:
      - .env
    command: ["--config", "/app/config.yaml", "--detailed_debug"] 

  openwebui:
    image: ghcr.io/open-webui/open-webui:0.4.7
    container_name: open-webui
    volumes:
      - open-webui:/app/backend/data
    ports:
      - 8080:8080
    depends_on:
    - db
    environment:
      WEBUI_AUTH: False
      ENABLE_OLLAMA_API: False
      OPENAI_API_BASE_URL: "http://litellm:4000"
      OPENAI_API_KEYS: "sk-124781258123"
      DEFAULT_MODELS: gpt-4o
      REDIRECT_URI: "http://localhost:8080/auth/callback"
      DATABASE_URL: postgresql://llmproxy:dbpassword9090@db:5432/openwebui
      ENABLE_RAG_WEB_SEARCH: True
      ENABLE_SEARCH_QUERY: True
      RAG_WEB_SEARCH_ENGINE: searxng
      SEARXNG_QUERY_URL: http://searxng:8888/search?q=<query>
    restart: unless-stopped
  
  db:
    image: postgres:latest
    environment:
      POSTGRES_USER: llmproxy
      POSTGRES_PASSWORD: dbpassword9090
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./initdb.d:/docker-entrypoint-initdb.d
  
  redis:  # New Redis service for caching
    image: redis:latest
    ports:
      - "6379:6379"
    restart: unless-stopped


volumes:
  litellm: {}
  open-webui: {}
  pgdata: 

networks:
  default:
    driver: bridge
